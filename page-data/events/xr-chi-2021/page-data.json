{"componentChunkName":"component---src-templates-event-js","path":"/events/xr-chi-2021","result":{"data":{"markdownRemark":{"frontmatter":{"title":"The First XR Remote Research Workshop @ CHI 2021"},"html":"<h1>Important Links &#x26; Dates</h1>\n<ul>\n<li><strong>Application Deadline:</strong> February 21st, 2021 (see below for details)</li>\n<li><strong>Final Decision Notification:</strong> March 1st, 2021</li>\n<li><strong>1-Day Workshop:</strong> 15 May JST 2200 – 16 May JST 0200 / 15 May EDT 0900-1300 / 15 May CEST 1500-1900</li>\n</ul>\n<hr />\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1440px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/38e1d892d090a27df822aacf610ab129/644c5/xr-chi-2021-headset.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 48.611111111111114%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAQBAgX/xAAVAQEBAAAAAAAAAAAAAAAAAAADBP/aAAwDAQACEAMQAAABqnsLzOySCv8A/8QAGhAAAgMBAQAAAAAAAAAAAAAAAAIDETIBBP/aAAgBAQABBQKd+oJJTUNnz5P/xAAWEQEBAQAAAAAAAAAAAAAAAAABECH/2gAIAQMBAT8BTZ//xAAYEQACAwAAAAAAAAAAAAAAAAABAhASMf/aAAgBAgEBPwFSK5H/xAAYEAEBAAMAAAAAAAAAAAAAAAABEAAiQf/aAAgBAQAGPwIOOaxv/8QAGxABAAICAwAAAAAAAAAAAAAAAQARECExQXH/2gAIAQEAAT8hqBoIoFS9UHMY28oAWu8f/9oADAMBAAIAAwAAABBMz//EABYRAQEBAAAAAAAAAAAAAAAAAAEQMf/aAAgBAwEBPxB3c//EABURAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAECAQE/EDOP/8QAGhABAQEBAAMAAAAAAAAAAAAAAREAMSFBYf/aAAgBAQABPxAygFZ35dVyYhzy9gYLiBQSu5TANcM93//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"VR headset\"\n        title=\"VR headset\"\n        src=\"/static/38e1d892d090a27df822aacf610ab129/644c5/xr-chi-2021-headset.jpg\"\n        srcset=\"/static/38e1d892d090a27df822aacf610ab129/158ba/xr-chi-2021-headset.jpg 360w,\n/static/38e1d892d090a27df822aacf610ab129/80e3c/xr-chi-2021-headset.jpg 720w,\n/static/38e1d892d090a27df822aacf610ab129/644c5/xr-chi-2021-headset.jpg 1440w\"\n        sizes=\"(max-width: 1440px) 100vw, 1440px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<hr />\n<h1>About the first CHI remote XR research workshop</h1>\n<p>HCI and social science experimentation that explores or uses extended reality (XR) has been particularly impacted by the recent Covid-19 pandemic. This is due to typical deployment of XR experiments inside laboratories, and a paucity of research into how to effectively conduct remote XR experimentation. This first CHI Remote XR workshop aims to explore the current state of the art around three main themes of remote XR experimentation:</p>\n<ol>\n<li>participant recruitment and screening;</li>\n<li>data collection, including limitations and affordances of existing research and XR tools</li>\n<li>software frameworks and requirements for the effective design of encapsulated remote XR user studies.</li>\n</ol>\n<p>This workshop brings together researchers and practitioners in XR to explore these recently emerged themes and to imagine how effective future remote XR research might be conducted.</p>\n<hr />\n<h1>Workshop Themes</h1>\n<h2>Participants: who are they, are they representative, and how do weaccess them?</h2>\n<p>The recruitment of online participants for non-XR experiments is generally considered effective, and often happens through platforms such as Amazon Mechanical Turk. While this approach has been used for XR studies, the use of XR-specific hardware has limited the participant pool (e.g. only 1.4% of Amazon Mechanical Turk respondents have access to head-mounted VRdisplays).</p>\n<p>Participants also may have to have access to a dedicated physical space (e.g. devices usually require an empty 2×2 metres, while AR experiments may need fixed locations), as well as other common experimental requirements (e.g. no distractions).</p>\n<p>This limited participant pool raises two questions: is it representative of wider populations, and how do we effectively access this smaller pool of users? To answer this, we need a better idea of who these users are and how to target them. In addition, it is important to understand ethical concerns of using participants in different countries and within different cultural/social/physical environments.</p>\n<h2>Data collection: identifying drawbacks of remote XR and advantages from the data collection affordances built-in to XR hardware</h2>\n<p>Laboratory settings allow researchers to setup and capture many different types of data from a participant, which have previously not been practical for remote XR studies (e.g. physiological data, external cameras, bespoke hardware interactions). It is reasonable to suggest that remote XR experiments are not yet able to easily recreate this level of data collection.</p>\n<p>However, modern XR-enabling hardware (such as consumer VR kits) allow for many types of data collection that were previously difficult to collect or required bespoke setups. Different variations of XR-hardware also enable further data collection (such as HMDs with in-built eye-tracking).</p>\n<p>There are also novel approaches to understanding human activity that are possible via XR-hardware that have previously used dedicated sensors, such as using microphones to measure exercise exertion or body or head movements for focus on interest and interactional attention.</p>\n<p>We believe it is important for the XR research community to outline both the limitations and potential of existing XR-hardware, as well as imagine what an idealised XR-hardware-as-data-collection device might look like.</p>\n<h2>Encapsulated studies: how can we lower the barriers to creating encapsulated experiment software, to maximise the potential of remote XR research</h2>\n<p>Software applications for XR development have been traditionally developed with the assumption of lab-based experimentation. Work is being done to simplify the data collection step for XR experiments built in Unity.</p>\n<p>However, there is not yet an approach that is dedicated to the requirements of remote studies. In fact, we still need to establish the requirements for the development of a software framework that allows the effective implementation of remote XR studies.</p>\n<p>This should not only include the data collection methods, but also libraries to transfer and store the data safely and easy-to-setup environments to run studies. This type of “encapsulated experiment” could also improve replication and transparency, as theorised by Blascovich, and allow for versioning of experiments, in which researchers can build on perfect replicas of other’s experimental environments and processes.</p>\n<p>Questions remain over what are the constant features that should be at the core of most XR remote research and that should necessarily be present and available for researches who want to deploy a remote XR user study.</p>\n<hr />\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1125px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d249f0dad064220ff681c4789f8b01d7/ec605/xr-chi-2021-cool-guy.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 66.66666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAUBAwT/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAABTXZ2cKySv//EABoQAAIDAQEAAAAAAAAAAAAAAAIDAAEREDH/2gAIAQEAAQUCH0l8G8jb1M//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAcEAABAwUAAAAAAAAAAAAAAAAhAAEQAhESMWH/2gAIAQEABj8COlkzWp7ARj//xAAZEAEBAQEBAQAAAAAAAAAAAAABACERMZH/2gAIAQEAAT8hI/RJzT+dSbItclN05N//2gAMAwEAAgADAAAAEG8f/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAHBABAAMAAgMAAAAAAAAAAAAAAQARMSFBUZGx/9oACAEBAAE/EDwkHLNCOvGBv+F+oYjhrsl8seY31G5qf//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"VR user\"\n        title=\"VR user\"\n        src=\"/static/d249f0dad064220ff681c4789f8b01d7/ec605/xr-chi-2021-cool-guy.jpg\"\n        srcset=\"/static/d249f0dad064220ff681c4789f8b01d7/158ba/xr-chi-2021-cool-guy.jpg 360w,\n/static/d249f0dad064220ff681c4789f8b01d7/80e3c/xr-chi-2021-cool-guy.jpg 720w,\n/static/d249f0dad064220ff681c4789f8b01d7/ec605/xr-chi-2021-cool-guy.jpg 1125w\"\n        sizes=\"(max-width: 1125px) 100vw, 1125px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<hr />\n<h1>Call for Participation</h1>\n<p>Research experiments in the XR/MR/VR field has traditionally taken place in dedicated space and laboratories and been supervised by the researcher. With COVID-19, the sudden transition to remote experimentation has left many researchers without opportunities to carry on their user studies. This is partially due to the lack of remote-oriented solutions for XR research.</p>\n<p>This workshop will bring together researchers and practitioners in XR research with the goals to:</p>\n<ul>\n<li>Reflect on the limitations of current participant recruitment for remote XR studies, and the requirements for effective on-going recruitment</li>\n<li>Identify the characteristics of existing XR research and explore the opportunities XR hardware brings to remote experimentation, as well as what other features might be implemented with a “research-oriented” approach</li>\n<li>Discuss the needs of a standardized software framework to conduct encapsulated remote XR experimentation and the benefits it might bring</li>\n</ul>\n<p><em>Participants should submit position papers (max 3 pages in <a href=\"https://chi2021.acm.org/for-authors/chi-publication-formats\">CHI ACM Master Article format</a>) about their XR research and practice addressing the themes listed at the workshop website</em>. Position paper submission is to <a href=\"mailto:f.soave@qmul.ac.uk\">f.soave@qmul.ac.uk</a>. Participants will be selected based on the quality of XR research and practice and with a view to creating a balance of topics in the workshop.</p>\n<p>Please note that at least one author of each accepted position paper must attend the workshop and that all participants must register for both the workshop and for at least one day of the CHI 2021 conference.</p>\n<hr />\n<h1>Workshop Structure</h1>\n<table>\n<thead>\n<tr>\n<th>Activity</th>\n<th>Time (minutes)</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Welcome</td>\n<td>10</td>\n<td>Workshop introduction</td>\n</tr>\n<tr>\n<td>Session 1</td>\n<td>45</td>\n<td>Discuss remote participant recruitement and the prototyping of a dedicated platform or process</td>\n</tr>\n<tr>\n<td>Coffee Break</td>\n<td>15</td>\n<td></td>\n</tr>\n<tr>\n<td>Session 2</td>\n<td>45</td>\n<td>Discuss the need an limitations for remote XR data collection, and affordances of XR hardware devices</td>\n</tr>\n<tr>\n<td>Lunch Break</td>\n<td>30</td>\n<td></td>\n</tr>\n<tr>\n<td>Session 3</td>\n<td>45</td>\n<td>Discuss software frameworks to be used by researchers for encapsulated remote XR experimentation</td>\n</tr>\n<tr>\n<td>Conclusion</td>\n<td>10</td>\n<td>Summary</td>\n</tr>\n</tbody>\n</table>\n<p>The workshop is designed to provide an opportunity for researchers to discuss the needs and limitations of remote XR practice. The aim, broadly, is to collaboratively imagine practical futures for idealised remote XR research processes, and outline the requirements to reach these.The workshop will take place in an online environment as a virtual activity during the conference.</p>\n<p>The structure of the workshop is summarised in the image above, and consists of three sessions, one for each theme outlined above: participant recruitment, XR hardware and data collection, and encapsulated experiments.</p>\n<p>Each of the first two sessions consist of two sprints: the first for discussing relevant prevalent challenges, and the second for imagining ways to overcome these. In each sprint, participants will be split into two breakout rooms to allow for more intimate, involved discussions. At the end of a sprint, the groups will reconvene to share results.</p>\n<p>The third session is an open discussion, partially based on learnings from the first two, and leveraging a cooperative shared annotation space for sharing and arranging ideas. The workshop will take place in a normal video conferencing application and additional platforms will be used for the interactive activities (e.g. Miro, Mural or Google slides). The total duration of the workshop, including breaks, will be 3.5 hours.</p>\n<hr />\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1440px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b4ae4e60d541afce190daf6b36ec8912/bd53b/xr-chi-2021-beard.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 66.66666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABQAE/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAATd52hFoej//xAAaEAEAAgMBAAAAAAAAAAAAAAABAAIDESEi/9oACAEBAAEFAh1auShK3NJ76DkZ/8QAFREBAQAAAAAAAAAAAAAAAAAAACH/2gAIAQMBAT8BV//EABURAQEAAAAAAAAAAAAAAAAAABAR/9oACAECAQE/Aaf/xAAaEAACAgMAAAAAAAAAAAAAAAAAEQECECJB/9oACAEBAAY/Ah9NqqRCx//EABkQAAMBAQEAAAAAAAAAAAAAAAABETFBkf/aAAgBAQABPyGc7g1m0sSGlaGcp6I9KjL4f//aAAwDAQACAAMAAAAQDP8A/8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQMBAT8Qg//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QH//EABwQAAIDAAMBAAAAAAAAAAAAAAERACExcYGRof/aAAgBAQABPxDEjA+QkMLD9m0L3mWgEJsR8gwYGqNRQSksUcadT//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"VR user\"\n        title=\"VR user\"\n        src=\"/static/b4ae4e60d541afce190daf6b36ec8912/644c5/xr-chi-2021-beard.jpg\"\n        srcset=\"/static/b4ae4e60d541afce190daf6b36ec8912/158ba/xr-chi-2021-beard.jpg 360w,\n/static/b4ae4e60d541afce190daf6b36ec8912/80e3c/xr-chi-2021-beard.jpg 720w,\n/static/b4ae4e60d541afce190daf6b36ec8912/644c5/xr-chi-2021-beard.jpg 1440w,\n/static/b4ae4e60d541afce190daf6b36ec8912/274e1/xr-chi-2021-beard.jpg 2160w,\n/static/b4ae4e60d541afce190daf6b36ec8912/bd53b/xr-chi-2021-beard.jpg 2250w\"\n        sizes=\"(max-width: 1440px) 100vw, 1440px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<hr />\n<h1>Post-Workshop Plans</h1>\n<p>Our aim for the workshop is to collect the needs and limitations of current XR research practices and to imagine how the future research in this field could be. With the information collected during the workshop we will:</p>\n<ul>\n<li>Circulate notes created in the workshop with participants</li>\n<li>Propose guidelines for the design of future research-oriented XR hardware, software frame-works and deployment platforms for remote XR user studies</li>\n<li>Prepare a journal paper on the themes of the workshop</li>\n</ul>\n<hr />\n<h1>Workshop Presentations</h1>\n<table>\n<thead>\n<tr>\n<th>                                                                                     </th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 600px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b251834ec53ae13a15c2b60825222a24/0a47e/xr-chi-2021-hoover.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 35.55555555555556%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAB50lEQVQozx3M308SAQDA8fs3arV86am3NnyordR01oOt5UKzpDJQEU5BRe68EwVCvOMOweP44eGByQ9Fy6Hl1tbWn/Zt8/mzfYT0toocDSF+niLinyGztY6WlNFSCk4pT1KJoW6sEAm8ZWFmjOCHEYIzwyzNjhL6NM6c9zn+qSF8k8+IiT6E3G7qNlSjIRRxESm0gBqLIEVCxJaDrEXCrAYDTAw94sXgAK+ePmR88B5jnruMDt5n+PEdRjwPGPYM8PH1E4T2sUvn5Jh/V9fc/OiTVLfJpTJUbZt9PUsmm2J9TSS48I4vvpf45yYIL3mJiF6Wl6cQw9NEoz4WF9+g6RJCpbBHRlqhGpynI4rEZr8yH99jNa6i78gE5t4z7ZvkoJEj72ro9SxWq0D5rIbtatQaGna3hNbQOe5UEZxamWwmiRFXqcvb5NMasuUi7dmYVpmdrI6c/sauVUE1SyRMG8WwiBeLJIomUq6AYpSRcmVyle8Irf5fap0r2r0bTs7/UDvtU+leUO7+wm5dYp1cYrf7pO0Wm2YdteCSyDdphm9oib8pxH+yWXJQjDqG20M46l1TaPQoNc8pNs4xnC7mYRfd6aDVWmiHbfbdM1JWE8V0SBy4bJlHFOULDLVDKttA2Xduzaif8h9qulycmIdISwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"xr chi 2021 hoover\"\n        title=\"xr chi 2021 hoover\"\n        src=\"/static/b251834ec53ae13a15c2b60825222a24/0a47e/xr-chi-2021-hoover.png\"\n        srcset=\"/static/b251834ec53ae13a15c2b60825222a24/f21e7/xr-chi-2021-hoover.png 360w,\n/static/b251834ec53ae13a15c2b60825222a24/0a47e/xr-chi-2021-hoover.png 600w\"\n        sizes=\"(max-width: 600px) 100vw, 600px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></td>\n<td><strong>Ensuring the Reliability of Remote VR Research Data</strong>. Melynda Hoover, Lucia Cherep, Jonathan Kelly, Stephen Gilbert <a href=\"https://www.youtube.com/watch?v=tcVIXldH3xs\">presentation</a></td>\n</tr>\n<tr>\n<td><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 581px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c55e10bc606d120b10e57eb00c13c8eb/f0d01/xr-chi-2021-ghasemi.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 66.3888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAQFAgP/xAAVAQEBAAAAAAAAAAAAAAAAAAABAP/aAAwDAQACEAMQAAAB74pKCsXSP//EABwQAAEEAwEAAAAAAAAAAAAAAAIAAQMSBBEiMf/aAAgBAQABBQIwJlW6fHk3P4A9r//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABsQAAEEAwAAAAAAAAAAAAAAAAABAhEhECKB/9oACAEBAAY/ApG7ckqVEG3j/8QAHBABAAMAAgMAAAAAAAAAAAAAAQARIRBxMUFR/9oACAEBAAE/IdMJvtJfQDVUPmHxDuAe6VVqss+vH//aAAwDAQACAAMAAAAQgP8A/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAERMf/aAAgBAwEBPxCMW//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAECAQE/EEf/xAAcEAEBAAMAAwEAAAAAAAAAAAABEQAhMRBRYcH/2gAIAQEAAT8Qa6FEw+uuKKeVQK53dyWhLUH7l2C0CnKJiMiU2zRv5zx//9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"xr chi 2021 ghasemi\"\n        title=\"xr chi 2021 ghasemi\"\n        src=\"/static/c55e10bc606d120b10e57eb00c13c8eb/f0d01/xr-chi-2021-ghasemi.jpg\"\n        srcset=\"/static/c55e10bc606d120b10e57eb00c13c8eb/158ba/xr-chi-2021-ghasemi.jpg 360w,\n/static/c55e10bc606d120b10e57eb00c13c8eb/f0d01/xr-chi-2021-ghasemi.jpg 581w\"\n        sizes=\"(max-width: 581px) 100vw, 581px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></td>\n<td><strong>Model-based Task Analysis and Large-scale Video-based Remote Evaluation Methods for Extended Reality Research</strong>. Yalda Ghasemi, Heejin Jeong <a href=\"https://www.youtube.com/watch?v=Olc2LomZRG8\">presentation</a></td>\n</tr>\n<tr>\n<td><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 600px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d40ac9e215bbdff3d4c644225048a706/0a47e/xr-chi-2021-ouverson.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 38.888888888888886%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAA7EAAAOxAGVKw4bAAACRUlEQVQozyXPTU+SAQDA8edQh7bEdCmFOloqms2XpqQSKaIiKCWI0wTMh6JImiUohQHGVDArTSzxDTJnqc0O1qarph6rdWhdOtpX+TfXF/htP0GtaaBe14yr182nz98Yn35DR5cdtbaFtfX3LCVWmF9cZmpyimgkislsQZYtp0ypIu9cKea2dkRRxOFwMDo6iqDVNiLedOHx+XkSf83j50sMPAig1hoYHYvybmOF7d19ZmfjJBNJrPYezuYXoWk0omnQU1Wt4kxWFrYuK5FIFKHkQiVNRjMPPT6GDUZaVLWcr1BRXK5CXaehSefjlnOGvb1dDg7+0t0jYum0sZhYpvu6SHmFkuxD0GojMhZBMKgv4w4ESVrMfJCepD8tndqLlyiqKEF+Kshx4TuCsE5seoffv37QZblGcGiY7Z0viE4Xmrp6FAoFdnv3//JQh5URt4eZ4hLm0lMIn5AQrD+sVJMn1ZF25CvHhFWmXrxla3ODPn07d+sMeNs6GHTfYzaeYD65ysCAj2AohDBpNJPocbJrMrEpTWdckkKfsoqyKjU6nRF56h9Sj35kYmKe8EiYO3UG2ls7ueFwctsmEnH1EQqO4B96ROgQ1F8x0RsIs+bxsn06g2iqBHetlkptI8+eLlCY/RPJ0S1exVaYiMUYbDYT7hQJ3PcT8gbw93oRa/S06lvo93gRmo0Waq524K/Vsi/LZCQzg5aCIgpLlUxOTuFy+fF5Y8zNLfIyvoDNZMEmleGQ5eCUynBlyXHmFpCfIydXUcg/8YxUpyPhTskAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"xr chi 2021 ouverson\"\n        title=\"xr chi 2021 ouverson\"\n        src=\"/static/d40ac9e215bbdff3d4c644225048a706/0a47e/xr-chi-2021-ouverson.png\"\n        srcset=\"/static/d40ac9e215bbdff3d4c644225048a706/f21e7/xr-chi-2021-ouverson.png 360w,\n/static/d40ac9e215bbdff3d4c644225048a706/0a47e/xr-chi-2021-ouverson.png 600w\"\n        sizes=\"(max-width: 600px) 100vw, 600px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></td>\n<td><strong>Adaptive Moderated Research: Lessons Learned in Redesigning a Moderated Virtual Reality Collaboration Study</strong>. Kaitlyn Ouverson, Angelica Jasper,Stephen B. Gilbert, Nick Wilson, Peggy Wu <a href=\"https://www.youtube.com/watch?v=nHipBhIcQPY\">presentation</a></td>\n</tr>\n<tr>\n<td><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 600px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/6e4c6fec7c788fe648bed3796cae2c84/0a47e/xr-chi-2021-ch.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.111111111111114%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADB0lEQVQoz22OW2yTBQCF/+gDGBPjo4kLiYQ3zBJMTEjESIyXRSViiA86xQ2ZGiBiFiVRtrgJ41rWbowxiookbV2d7hIGo5tjhQ4G/O3Wshpa+996+bt2fy9b51bZpZ8ZDzx5ki85OefhHOG16jPsa+ihrnWEAy1uDp4d5cszHmo7blK+28lzlTbW77Sz4WM7mz51sLnmVzbvdlCxz8k3Ry/zyl4na9/7CeFdK4+9fRqh9ccbxPUUwwMDjI2O4vP5yBtxMukYpoteqhtH2HXITfVhNx99f40dB/9kx3dD1PwwTJ35BqaOmxwwuan4+gpv1vYgjF7p4tRJC8+seZrydc/zSWUN4xO3CQVFVDnOoEfF5dHwBxR89xL0u1U6ByR+d8n84ZLoGYzQczVM56UQbbYAgrWtiuNNTVRs2Ijts0omb11D0yUmBrrIxSSyhoGRSjGbz1OcL5DNzRGMTBNRUkSUaWQtTzI5h6Jlcd+NIbz8/lYcdhuuZgthj5tkJkooIDLys5Vw5G+m9Dg5XUO7f4/phEYurVPIppnNGEzpKVzX71J7pINXq/bzwvYPEIT1m3DYnVy3/oLH2c3t3j6cDUcJ9zr4sP40r+834RUnuO/zEhi7Q3DCz5BbpPvyCHsazWzctpNnt7xF2UtbWPdiOcLjZWW0NLfQf8yCo+E4QxdsDJ5rI/hbB58faufWpMyqSquU4MHiCnMLi8z+s0CuUODB4hIrpWUorbAwP48gPLmWUxYz/Sda6T1iZsh6gavn2uk638beukbCapT0lI6iqsiyTDweQ5ElolGNqWQSSZJQFAVZkllaWkIo2/YEJ9rrsR8203msmWGbg8lJL9PpFOd7TUQSIXKZPKJXJOD3EwwG8Xq9jI/7EEXxoV/NkskkxWIR4antAtZLzfyf+sY78Us+ivP/YhgGmUyWaCyGuvpIVkjoOjMzMw8pFArkcjmENW8I7LFU0TfWTUufiZPd9Xx78Su+OLuLd5q2omcSjwbU1CyxuEFJ0/grkuVOSCU/V3jULy8v8x8mI6u9OFfVAQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"xr chi 2021 ch\"\n        title=\"xr chi 2021 ch\"\n        src=\"/static/6e4c6fec7c788fe648bed3796cae2c84/0a47e/xr-chi-2021-ch.png\"\n        srcset=\"/static/6e4c6fec7c788fe648bed3796cae2c84/f21e7/xr-chi-2021-ch.png 360w,\n/static/6e4c6fec7c788fe648bed3796cae2c84/0a47e/xr-chi-2021-ch.png 600w\"\n        sizes=\"(max-width: 600px) 100vw, 600px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></td>\n<td><strong>Conducting a Remote Virtual Reality Experiment during COVID-19</strong>. Nabil Ch, Alberta A. Ansah, Atefeh Katrahmani, Julia Burmeister, Andrew L. Kun, Caitlin Mills, Orit Shaer, John Lee <a href=\"https://www.youtube.com/watch?v=_O-UGJ33YNA\">presentation</a></td>\n</tr>\n<tr>\n<td><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 600px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c83e1ead415da3d6b1580f3c6fc6cd3d/0a47e/xr-chi-2021-jialang.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 57.22222222222223%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAA7EAAAOxAGVKw4bAAACmklEQVQoz3WSy0uUYRTG509oFdG2ZdCiVdAiaBEthSwyMbsoLVIpwiiMTCINuliUaKKTlxHHSzPqaDoz3zcz39wKmYvjzHeZby4VFQkuyoRa/uJ9xaBFi4fnnJdzzvuciyOX19HepVESabwBjVIhxkcrTtV6j2GYFItFLMvCNAzUqMbkgy4enj5K/eUWzjTdor6xhtrzl7jYeo98Po8jlUoxNjaK1/MGz+wMrgk3w85Rxl2TBINByuUytm1jGDpqRGO8p4OX94/S3dtLe2cv3Y+f8PB5H8/7hzBNC8f6+jqKosjkQDAo7VBIZWVlBVVVSafTiBjTNPHOzTHjmcPrXeaN14d7xoM/GCISCRPTVBnjyOVyMlEgFAr9Y2uaxurqKmtrazJ4ZGyCF/2D9A0O8WrIyfT0FAsLc8zPe1nwzaPrhR2FkUjkb4FwOCwh3oQvWHxqGAZKNEbS6yE+8Jopd0bOXnuXwTBNdMOQMY5sNksgEMDv98s2hS14119aWpIF5RxNnY2qza9vX/i9tc3W9k++/9hkY/Mrnz5XKJeLOwrj8TiJREJyNBolmUwSi8WkQsFFyyKeeM/Tl4M4J9w8Gxyjz+mmb3iKrp4Rbnc6absxwKwnvKPQ5/NJJYuLi5IFxHJE62JZ2WwGvxKhrvkmpxpuc7aphYbLLdQ01LHvYAf7Dzxiz94O7txdxlEoFMhkMn8hFiA2q+s6pVIJyypSqZRRwxr1TXc5duIRtRf6uXRhmuN1tRw518jhumscOnmdx7OjOMTR2sWiPOBdiHnJYzZNOWhR0K+EqW9u5+KVF1xtTdLWWqF70oVLdRFUErg8iyhJDYdQ8X+UJVerVVLpLAtvA+TWs9j2Gh/KeVJGgrS+SqVkY+gFbMvmD9lSsWA2ie4qAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"xr chi 2021 jialang\"\n        title=\"xr chi 2021 jialang\"\n        src=\"/static/c83e1ead415da3d6b1580f3c6fc6cd3d/0a47e/xr-chi-2021-jialang.png\"\n        srcset=\"/static/c83e1ead415da3d6b1580f3c6fc6cd3d/f21e7/xr-chi-2021-jialang.png 360w,\n/static/c83e1ead415da3d6b1580f3c6fc6cd3d/0a47e/xr-chi-2021-jialang.png 600w\"\n        sizes=\"(max-width: 600px) 100vw, 600px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></td>\n<td><strong>Challenges in Running Social VR Studies. A Tale of a Covid Procedural Pivot</strong>. Victor Jialang Li, Sean Fernandes, Joshua Mcveigh-Schultz, Kathering Isbister <a href=\"https://www.youtube.com/watch?v=E0y2nTWkhYA\">presentation</a></td>\n</tr>\n<tr>\n<td><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 522px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/988c97ace876733cc046ec332dda5388/29492/xr-chi-2021-gnacek.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 73.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADjElEQVQ4y4WTe0xbdRTH+59/GLMscRoTjcZITCYamMONDbMxeTSAzPkYYYh0sKiMQgFlKJtkrI6XQ4gYNmBzc7IK5TmVR5GHPBTHaGETHbPIc+ACFJy0pfS2/ZjeQoOJiSe5v9+9v3PO5/6+5+RIAATBzsyShWmTgMPh4P+sQl1PlDyd270tMKpntWccZ5bD7kACDvQ37tLcPU1h/wL6Fei7puNqazc1je1UN7bxVW0TTR0/ounqY+neMseVeTzkvYeKjCTQaDBe6l4D2pEIxlVG20bp75xA3X2HvnmBki+rySosp7qxna+vavii8htOFZ3nTGkFTR0/UVhyHi/pa1Tln4Gyy1g6B1xAm911w/lrU9xq0fO9Zow7ixZMJhOj49NMzfyJ0WR2SxUEgXvLRvqva1FV1TKkG2KouZXZqWnRb7eLQHAINkxzRv5eNGO32bDZbG6Is6TOb2fwus3OzDL8yzDaAR36iUmENb+z/hLn8l9tWJi7y6+D17FaVtx/3wh1vo+MjCBYrf86E4HrgXNz81TV1JOdX0DUq68QsN2TyFB//tDfXr8vKysrfFb8ObLDcRyVJyI7HEteXj7Ly8tihAgUBJdElbqWh594mkc9PNm05RHuf2Azb0v90LV/J/pNRiMp773Pi/4BBEhDxUcaFo40JIzYuCMYDIY1oHVVTOjTfEvcgXAUEa+z3+sZPB7cTMHRSMY66xBsLhXpHx5np99e/AOl7HkpWITuDQgi65RyTfKGurSVfEzlp7mM9XZQFh3K5ZRoarMTkB/a766zTjfIO/Fy4hOSSFSkoEhOJS39A37X612S7Q74a2yEztJcbnZpmBns59xHKYQ8+xjakiwupsYS4bOV8Z5WV8s32MYmuZtivqVF9W4k+TERtBR/wkmpH9u23MfLzz2F5kQyVxJj0WQmU6OIYVz7s5hYX1eHIimJvNxcjh1Lo6GhwQ2VDBeeIDNwF29ufZJUXy8U+55n9+ObyDsYQldOBjmR4VxKlHEx/hDa9mZUVWp8d+3Gy9uboOBgfF7YwY6dvpw7e5alpSUkNyov0F5aRFtZMRO9baQEbiN6uwdquYwrilgyDwSRGxnGhWQZ+t9uolQqUSpPExUdw1sxMnE/nZ3DycxMJicnXZPiNpsFVcIbFBwM5gdlGuVxEWSE7eOIjyeN5UViiHZggIWFecxmM1arVRzTRYOB3p4eUfI/dIWvhRyZBWMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"xr chi 2021 gnacek\"\n        title=\"xr chi 2021 gnacek\"\n        src=\"/static/988c97ace876733cc046ec332dda5388/29492/xr-chi-2021-gnacek.png\"\n        srcset=\"/static/988c97ace876733cc046ec332dda5388/f21e7/xr-chi-2021-gnacek.png 360w,\n/static/988c97ace876733cc046ec332dda5388/29492/xr-chi-2021-gnacek.png 522w\"\n        sizes=\"(max-width: 522px) 100vw, 522px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></td>\n<td><strong>Remote Collection of Physiological Data in a Virtual Reality Study</strong>. Michal M.G. Gnacek, Ellen E.S. Seiss, Theodoros T.K. Kostoulas, Emili E.B. Balaguer-Ballester, Charles C. Nduka <a href=\"https://www.youtube.com/watch?v=1snh2wMsHHM\">presentation</a></td>\n</tr>\n<tr>\n<td><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 562px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/62cce77a04bde1c040140bf655ade5ba/6e88f/xr-chi-2021-sajjadi.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 68.61111111111111%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAC80lEQVQ4yz1U32sbRxDW35bnvPSx0McWCn0ufWoDhaQPotAY+tL2oaHQQAUNMU0cEixcC6cFJyR1EteWHF9t6Xw6SXenPd3t75mv7CrRwsDM7HyzM7Pfbsd7D2aGZ+AyW2CxmMNUObLpFEI5DwDeuwER9UMcM0efMQaTyQTvfBvpSKXCPsg7OGuxrCoIIWDqAjJ54f1qAQYGVVX1nXMgYs8MSCmRJAmCDyCAGUSETitlACAeC0AqDSaHo1GKT2/e9XvPhsE9KMqyb60FM/mQwHsHpSS0deg+fIu9kyLiO+p9hU++Be18A291tA/OBK5tnfrtoyomnBdlH+xxsZD+xr0R0nKNU8bjkzv/onc4fZ9QU8jXu32Lfu3eICVVtA9GJV3rPnfbL2Yhbl+s2t1Q2Zu0cde3jmg4bWKcMp4+vnNCvcM82h2tdez/5pM5vno0Q6tdPOnlhcBnvxxjcFoG8+9WqkGocFIqdB+e46oKFTKUcdh6fI7B6buWnXNhSEMt22GzqqMexBg7nKTZSSvlFTPfddb+TEQXTPR6JZbHADaymOXHq7qOegdA5r3LJpNJlqaTLKw8z7OrNM3yaZYaY1YA7jNzj5kFgLExJr28HKdZlqVJkqRSqRRAysxpZ00FwqppUNc1xuMxsiyDWDWYlyLSgpn/stb+GXhGzNDGYikEiqKAqOvIDKLAQ4otc1hxIAA3bcsgy4PRkj//beQaHQjF+8aYXVqHhSFHTFGUG1wQIuaOjcRk1K1GqwwiBsCDozk++vGNr6UN+wOtTT/4RWv9WVbDE615azy+e5zgWSLWl2Kdi9m/6J3yT/vjzWkP/lnwhz+8drWKtz5opN4Nys6rhbt++yU3eo0T0vEH37/i35/Pot2xdk2T7qP/NuQM6+moxNf3z9BEGvGB1GYv+A/Pl/jy3hmUXb+tQLNbf7zF01G1rpCIglY1q7rSWkU9SF3X1SzPC+fiB7HjnNsOL9QaU9RCVMwcxVlb5dNp1TRNxP0P4WUUWGciac0AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"xr chi 2021 sajjadi\"\n        title=\"xr chi 2021 sajjadi\"\n        src=\"/static/62cce77a04bde1c040140bf655ade5ba/6e88f/xr-chi-2021-sajjadi.png\"\n        srcset=\"/static/62cce77a04bde1c040140bf655ade5ba/f21e7/xr-chi-2021-sajjadi.png 360w,\n/static/62cce77a04bde1c040140bf655ade5ba/6e88f/xr-chi-2021-sajjadi.png 562w\"\n        sizes=\"(max-width: 562px) 100vw, 562px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></td>\n<td><strong>Reflections on Remote XR Experiments During the COVID-19 Pandemic</strong>. Pejiman Sajjadi, Jiayan Zhao, Jan Oliverwallgrun, Mahda M. Bagher, Alexander Klippel <a href=\"https://www.youtube.com/watch?v=QtewAKSSAZw\">presentation</a></td>\n</tr>\n<tr>\n<td><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 600px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/746a075a119cea4a9eba1a8ad9143873/0a47e/xr-chi-2021-mathis.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.388888888888886%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAA7EAAAOxAGVKw4bAAACcElEQVQoz1WSSW/TQBiG/S85cgOEVJaWLkRsoqgHlh+AuAC3XnpBLFVABAqoK92gJU6cOHZix8t4i90sTvsgTymIkR5pNIdn3vneUe5vC25t+TzZFzzc+5/H+4I7Wx53dyOy4QjPdfE8jyAIcByHKIqwbZujo4xGw0HTbJTShssrTTAe9InSI3pZX1Lsj4dDKq2A0nchhVq9hi+EFLVaLfI8p16v4/k+xRqP81Ph21aM7YaobUHV9FHbPoeGh+VGrHQSbm4JBvmYKAxkom63KylSuq7LYDCQwuFwiHJz3aFsRHCck/Qy4jgljHqEcQr5iFUrpvQ9QEQJvSSWEt/3CcOQarUqL8iyjJOTE0ajEUoxo6c/PDbthC+dhG/WKV+thI1uwvMDlzu7EabV5dfhAaqqomkanXZbCguKs/F4TJ6PUBZ2Bdc2QybWfC5W2pJLnzqSiVWPqxsB8/sxpu1QU1Up0LQ6lmVRU2tyhs1G85/wwY7P9FbIzLrH1YrBlTM+tphZ85jeENzfi+k4Lk1Nw/U8kiSWM1SrKrquy4KK545GQ5SFvZCZ7YjZnZi5gu2I0l5CaT9l7mePqYOU+YOUtu3QNk3ZcL/fl9+n0WhgmqbkbCn3Vg0mvlhMV3QmV9pc/2Zzudzg0psq00s1Zl/sMP+1iy0CDF2XyYJAyHabzaZMV5ydtm+jzK3oXKh0uPFBY/KzyeSqw/mlH5x7ucbUs22mHnzgdtnAT1O6loUQgjRN/yYshIZh8OjRYxYXF1HKTZ/XDcE7PWBZFyw3BWUj5L0ZsdwJeWXFvGsJkiThKEvJ0h5pQS+Rs+z9oSjMaOn8BvX6CVE/eMSbAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"xr chi 2021 mathis\"\n        title=\"xr chi 2021 mathis\"\n        src=\"/static/746a075a119cea4a9eba1a8ad9143873/0a47e/xr-chi-2021-mathis.png\"\n        srcset=\"/static/746a075a119cea4a9eba1a8ad9143873/f21e7/xr-chi-2021-mathis.png 360w,\n/static/746a075a119cea4a9eba1a8ad9143873/0a47e/xr-chi-2021-mathis.png 600w\"\n        sizes=\"(max-width: 600px) 100vw, 600px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></td>\n<td><strong>Remote XR Studies: The Golden Future of HCI Research?</strong> Florian Mathis, Xuesong Zhang, Joseph O’Hagan, Daniel Medeiros, Pejman Saeghe, Mark Mcgill, Stephen Brewster, Mohamed Khamis <a href=\"https://www.youtube.com/watch?v=cY1uiOuebvI\">presentation</a></td>\n</tr>\n<tr>\n<td><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 600px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/2ab8bf13b14d1e5727c907266aa3bdae/0a47e/xr-chi-2021-zhao.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.111111111111114%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAB5ElEQVQoz5WTe2vUQBTF82n9WgqCBRERdxG1xdJKfUAVS/rYNrvNY7OvdPPYzSaTzCT5yYy7Uu0/euDAnZuZc+/MubG6ruN/2HYtGqu6IhaliZ+OBnxMIxNbZiMYajwQaFuaLZVm19EoyXw6xxn59N7uc/imx/HRCbVUWK0+qBSohqZt+BtapNTfd9hWTpcJF7ZD/+iEJ18O6X04RqkGi64jyBJO4xk3dwsGyZJaSiopEVKyqSrKujY5qZRhJWtK0XC3HuBGn7mNYvzARwiBpau9Dxwe7b+g7Fq8+I7TkcOZ5zKYhNi+x+nQ4XoScjUO+D4acjn2+TYa4kVj2q6kazqklDRN80vw/HbI43d9c5UoS7E9l9Fsih8tmMRLLgKfy8DHnc9wphMjrNfeIvrzHX6b0rbmihshKKqKVVGQi5JCCCqlyMuSjVIUSu8pSfKcdVGQFRvWZWGeQ5untaz7juqW1T1qw1zXJa8EVRgiFgu0bW3Hg852SyO4c3MX78ZHw7ZtsjwnHgzIw9Dk8myJF8YEszXXNxf8sM84vzo3TZixmVclE1EgGvVgFrcJ9Di322LTsUPv4CsHn6549fI5e3vP6PdfG2OsqBKsZG0O/cufoqGfJstS0jQmSzOSJKHYbIwpPwHinUhYiXKt5wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"xr chi 2021 zhao\"\n        title=\"xr chi 2021 zhao\"\n        src=\"/static/2ab8bf13b14d1e5727c907266aa3bdae/0a47e/xr-chi-2021-zhao.png\"\n        srcset=\"/static/2ab8bf13b14d1e5727c907266aa3bdae/f21e7/xr-chi-2021-zhao.png 360w,\n/static/2ab8bf13b14d1e5727c907266aa3bdae/0a47e/xr-chi-2021-zhao.png 600w\"\n        sizes=\"(max-width: 600px) 100vw, 600px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></td>\n<td><strong>Remote Mobile Augmented Reality for Spatial Cognition</strong>. Yu Zhao, Soumyajit Chakraborty, Jeanine Stefanucci, Sarah H. Creem-Regehr, Bobby Bodenheimer <a href=\"https://www.youtube.com/watch?v=lckAL3xkdl0\">presentation</a></td>\n</tr>\n<tr>\n<td><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 513px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/7239ff16987e8e6eb79e490e37490a38/3047a/xr-chi-2021-bryce.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 75%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIFBP/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHc0lyuRhP/xAAaEAEBAAIDAAAAAAAAAAAAAAABAgASAxMx/9oACAEBAAEFAlNW5OM8YdUpDvM//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQIBAT8Bh//EABoQAAMAAwEAAAAAAAAAAAAAAAABIRASMVH/2gAIAQEABj8CsK5hLwXB6tH/xAAZEAADAQEBAAAAAAAAAAAAAAAAARExIYH/2gAIAQEAAT8hopoFyNKaOpmGIsWqvEJmbd6f/9oADAMBAAIAAwAAABAUH//EABcRAQEBAQAAAAAAAAAAAAAAAAEAEUH/2gAIAQMBAT8QXlpf/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAER/9oACAECAQE/EDK//8QAGRABAAMBAQAAAAAAAAAAAAAAAQARMSFB/9oACAEBAAE/ED3N1vAjYbuuiqgByAKfIX17end4wQNWjVzOVUap857RP//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"xr chi 2021 bryce\"\n        title=\"xr chi 2021 bryce\"\n        src=\"/static/7239ff16987e8e6eb79e490e37490a38/3047a/xr-chi-2021-bryce.jpg\"\n        srcset=\"/static/7239ff16987e8e6eb79e490e37490a38/158ba/xr-chi-2021-bryce.jpg 360w,\n/static/7239ff16987e8e6eb79e490e37490a38/3047a/xr-chi-2021-bryce.jpg 513w\"\n        sizes=\"(max-width: 513px) 100vw, 513px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></td>\n<td><strong>Remote Virtual Reality User Studies</strong>. Louise Bryce, Mark Sandler <a href=\"https://www.youtube.com/watch?v=2OcP6od10mo\">presentation</a></td>\n</tr>\n<tr>\n<td><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 600px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/2edbdc9063cbc207d5c0efe5aa632065/b4294/xr-chi-2021-saffo.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 41.388888888888886%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAIF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB2KCgf//EABcQAQEBAQAAAAAAAAAAAAAAAAIhADH/2gAIAQEAAQUCVSuPP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABcQAAMBAAAAAAAAAAAAAAAAAAABITH/2gAIAQEABj8CVIzT/8QAGhABAAMAAwAAAAAAAAAAAAAAAQARITFBUf/aAAgBAQABPyHQMnJPRJglmu2f/9oADAMBAAIAAwAAABCDz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABkQAQADAQEAAAAAAAAAAAAAAAEAESExUf/aAAgBAQABPxDbASWJcTvgcPGIZSKQ1n//2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"xr chi 2021 saffo\"\n        title=\"xr chi 2021 saffo\"\n        src=\"/static/2edbdc9063cbc207d5c0efe5aa632065/b4294/xr-chi-2021-saffo.jpg\"\n        srcset=\"/static/2edbdc9063cbc207d5c0efe5aa632065/158ba/xr-chi-2021-saffo.jpg 360w,\n/static/2edbdc9063cbc207d5c0efe5aa632065/b4294/xr-chi-2021-saffo.jpg 600w\"\n        sizes=\"(max-width: 600px) 100vw, 600px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></td>\n<td><strong>Two Paths Towards the Future of Remote Studies using Social VR</strong>. David Saffo, Sara Di Bartolomeo, Liudas Panavas, Caglar Yildirim, Cody Dunn <a href=\"https://www.youtube.com/watch?v=x5E47nqVBso\">presentation</a></td>\n</tr>\n<tr>\n<td></td>\n<td><strong>Researchers’ and Participants’ Experiences on Distributed User Studies Conducted in the First Year of COVID-19 Pandemic</strong>. Anil Ufuk Batmaz, Domenick Mifsud, Anthony Steed, Wolfgang Stuerzlinger, Francisco R. Ortega <a href=\"https://youtu.be/NI4UYPdQKDw\">presentation</a></td>\n</tr>\n<tr>\n<td></td>\n<td><strong>Some Lessons Learned Running Virtual Reality Experiments Out of the Laboratory</strong>. Anthony Steed, Daniel Archer, Ben Congdon, Sebastian Friston, David Swapp, Felix J. Thiel <a href=\"https://www.youtube.com/watch?v=x5E47nqVBso\">presentation</a></td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h1>About</h1>\n<p>This workshop is organised by:</p>\n<ul>\n<li>Jack Ratcliffe, PhD candidate at Queen Mary, University of London</li>\n<li>Francesco Soave, PhD candidate at Queen Mary, University of London</li>\n<li>Melynda Hoover, PhD student at Iowa State University</li>\n<li>Dr. Francisco Ortega, Assistant Professor at Colorado State University</li>\n<li>Dr. Nick Brynn-Kinns, Professor at Queen Mary, University of London</li>\n<li>Laurissa Tokarchuk, Senior Lecturer at Queen Mary, University of London</li>\n<li>Ildar Farkhatdinov, Lecturer at Queen Mary, University of London</li>\n</ul>\n<hr />\n<h1>Contact</h1>\n<p>Please contact <a href=\"mailto:f.soave@qmul.ac.uk\">f.soave@qmul.ac.uk</a> for questions.</p>\n<hr />"}},"pageContext":{"category":"events","slug":"xr-chi-2021"}},"staticQueryHashes":[]}